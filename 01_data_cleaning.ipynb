{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Data Cleaning Pipeline\n",
    "\n",
    "**Step 4: Clean the Data**\n",
    "\n",
    "This notebook covers:\n",
    "- 4.1 Load and Inspect\n",
    "- 4.2 Remove Cancellations and Bad Values\n",
    "- 4.3 Standardize Descriptions\n",
    "- 4.4 Add Derived Columns\n",
    "- 4.5 Save Clean Files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /Users/alihasan/retail-pricing-mba\n",
      "DATA_CLEAN: /Users/alihasan/retail-pricing-mba/data_clean\n",
      "OUTPUTS: /Users/alihasan/retail-pricing-mba/outputs\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "def project_root(start: Path = None) -> Path:\n",
    "    here = start or Path.cwd()\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"data_raw\").exists() or (p / \"outputs\").exists() or (p / \"data_clean\").exists():\n",
    "            return p\n",
    "    return here\n",
    "ROOT = project_root()\n",
    "DATA_CLEAN = ROOT / \"data_clean\"\n",
    "OUTPUTS = ROOT / \"outputs\"\n",
    "DATA_CLEAN.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUTS.mkdir(parents=True, exist_ok=True)\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"DATA_CLEAN:\", DATA_CLEAN)\n",
    "print(\"OUTPUTS:\", OUTPUTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "# Set plotting style - use a compatible style\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except:\n",
    "    try:\n",
    "        plt.style.use('seaborn')\n",
    "    except:\n",
    "        plt.style.use('default')\n",
    "        print(\"‚ö†Ô∏è  Using default matplotlib style\")\n",
    "\n",
    "# Set seaborn style safely\n",
    "try:\n",
    "    sns.set_palette(\"husl\")\n",
    "    sns.set_style(\"whitegrid\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Using default seaborn settings\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Project root set to: /Users/alihasan/retail-pricing-mba\n",
      "üìÇ Clean data folder: /Users/alihasan/retail-pricing-mba/data_clean\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# üìÇ Set up project root paths\n",
    "# ---------------------------\n",
    "from pathlib import Path\n",
    "\n",
    "def project_root():\n",
    "    \"\"\"\n",
    "    Walks up folders until it finds your project root\n",
    "    (the one with data_raw/ and data_clean/).\n",
    "    \"\"\"\n",
    "    here = Path.cwd()\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"data_raw\").exists():\n",
    "            return p\n",
    "    return here\n",
    "\n",
    "ROOT = project_root()\n",
    "DATA_CLEAN = ROOT / \"data_clean\"\n",
    "DATA_CLEAN.mkdir(parents=True, exist_ok=True)  # create if missing\n",
    "\n",
    "print(f\"üìÇ Project root set to: {ROOT}\")\n",
    "print(f\"üìÇ Clean data folder: {DATA_CLEAN}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading online retail data...\n",
      "‚úÖ Data loaded successfully!\n",
      "üìä Shape: 525461 rows √ó 8 columns\n",
      "\n",
      "üîç First 5 rows:\n",
      "  Invoice StockCode                          Description  Quantity  \\\n",
      "0  489434     85048  15CM CHRISTMAS GLASS BALL 20 LIGHTS        12   \n",
      "1  489434    79323P                   PINK CHERRY LIGHTS        12   \n",
      "2  489434    79323W                  WHITE CHERRY LIGHTS        12   \n",
      "3  489434     22041         RECORD FRAME 7\" SINGLE SIZE         48   \n",
      "4  489434     21232       STRAWBERRY CERAMIC TRINKET BOX        24   \n",
      "\n",
      "          InvoiceDate  Price  Customer ID         Country  \n",
      "0 2009-12-01 07:45:00   6.95      13085.0  United Kingdom  \n",
      "1 2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
      "2 2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
      "3 2009-12-01 07:45:00   2.10      13085.0  United Kingdom  \n",
      "4 2009-12-01 07:45:00   1.25      13085.0  United Kingdom  \n",
      "\n",
      "üìã Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 525461 entries, 0 to 525460\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   Invoice      525461 non-null  object        \n",
      " 1   StockCode    525461 non-null  object        \n",
      " 2   Description  522533 non-null  object        \n",
      " 3   Quantity     525461 non-null  int64         \n",
      " 4   InvoiceDate  525461 non-null  datetime64[ns]\n",
      " 5   Price        525461 non-null  float64       \n",
      " 6   Customer ID  417534 non-null  float64       \n",
      " 7   Country      525461 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
      "memory usage: 32.1+ MB\n",
      "None\n",
      "\n",
      "üìà Summary statistics:\n",
      "            Quantity                    InvoiceDate          Price  \\\n",
      "count  525461.000000                         525461  525461.000000   \n",
      "mean       10.337667  2010-06-28 11:37:36.845017856       4.688834   \n",
      "min     -9600.000000            2009-12-01 07:45:00  -53594.360000   \n",
      "25%         1.000000            2010-03-21 12:20:00       1.250000   \n",
      "50%         3.000000            2010-07-06 09:51:00       2.100000   \n",
      "75%        10.000000            2010-10-15 12:45:00       4.210000   \n",
      "max     19152.000000            2010-12-09 20:01:00   25111.090000   \n",
      "std       107.424110                            NaN     146.126914   \n",
      "\n",
      "         Customer ID  \n",
      "count  417534.000000  \n",
      "mean    15360.645478  \n",
      "min     12346.000000  \n",
      "25%     13983.000000  \n",
      "50%     15311.000000  \n",
      "75%     16799.000000  \n",
      "max     18287.000000  \n",
      "std      1680.811316  \n",
      "\n",
      "‚ùì Missing values:\n",
      "Invoice             0\n",
      "StockCode           0\n",
      "Description      2928\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "Price               0\n",
      "Customer ID    107927\n",
      "Country             0\n",
      "dtype: int64\n",
      "\n",
      "üè∑Ô∏è  Column names:\n",
      "  1. Invoice\n",
      "  2. StockCode\n",
      "  3. Description\n",
      "  4. Quantity\n",
      "  5. InvoiceDate\n",
      "  6. Price\n",
      "  7. Customer ID\n",
      "  8. Country\n",
      "\n",
      "‚úÖ Raw data loaded: 525,461 rows √ó 8 columns\n",
      "üìÖ Date range: 2009-12-01 07:45:00 to 2010-12-09 20:01:00\n"
     ]
    }
   ],
   "source": [
    "# Import our inspection function from src module\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Fix the path issue - we need to go up one level from notebooks/\n",
    "current_dir = os.getcwd()\n",
    "if 'notebooks' in current_dir:\n",
    "    # We're in notebooks folder, go up one level\n",
    "    os.chdir('..')\n",
    "    print(f\"üìÅ Changed working directory to: {os.getcwd()}\")\n",
    "\n",
    "from src.data_inspection import load_and_inspect_data\n",
    "\n",
    "# 4.1 Load and inspect (using our function)\n",
    "df_raw = load_and_inspect_data()\n",
    "\n",
    "if df_raw is not None:\n",
    "    print(f\"‚úÖ Raw data loaded: {len(df_raw):,} rows √ó {len(df_raw.columns)} columns\")\n",
    "    print(f\"üìÖ Date range: {df_raw['InvoiceDate'].min()} to {df_raw['InvoiceDate'].max()}\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to load data. Please check the file path.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Remove Cancellations and Bad Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Starting with 525,461 rows\n",
      "üíæ Memory usage: 131.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df_raw.copy()\n",
    "print(f\"üìä Starting with {len(df_clean):,} rows\")\n",
    "print(f\"üíæ Memory usage: {df_clean.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è  Removed 10,206 cancellation rows\n",
      "üìä Rows after removing cancellations: 515,255\n"
     ]
    }
   ],
   "source": [
    "# Remove cancellations (invoices starting with 'C')\n",
    "cancellations = df_clean['Invoice'].str.startswith('C', na=False).sum()\n",
    "df_clean = df_clean[~df_clean['Invoice'].str.startswith('C', na=False)]\n",
    "print(f\"üóëÔ∏è  Removed {cancellations:,} cancellation rows\")\n",
    "print(f\"üìä Rows after removing cancellations: {len(df_clean):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è  Removed 2,121 rows with bad quantities (‚â§0)\n",
      "üóëÔ∏è  Removed 3,690 rows with bad prices (‚â§0)\n",
      "üìä Rows after removing bad values: 511,565\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with negative or zero quantities and prices\n",
    "bad_quantities = (df_clean['Quantity'] <= 0).sum()\n",
    "bad_prices = (df_clean['Price'] <= 0).sum()\n",
    "\n",
    "df_clean = df_clean[(df_clean['Quantity'] > 0) & (df_clean['Price'] > 0)]\n",
    "print(f\"üóëÔ∏è  Removed {bad_quantities:,} rows with bad quantities (‚â§0)\")\n",
    "print(f\"üóëÔ∏è  Removed {bad_prices:,} rows with bad prices (‚â§0)\")\n",
    "print(f\"üìä Rows after removing bad values: {len(df_clean):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è  Removed 103,901 rows with missing Customer ID\n",
      "üóëÔ∏è  Removed 0 rows with missing Description\n",
      "üìä Rows after removing missing data: 407,664\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing Customer ID or Description\n",
    "missing_customer = df_clean['Customer ID'].isnull().sum()\n",
    "missing_description = df_clean['Description'].isnull().sum()\n",
    "\n",
    "df_clean = df_clean.dropna(subset=['Customer ID', 'Description'])\n",
    "print(f\"üóëÔ∏è  Removed {missing_customer:,} rows with missing Customer ID\")\n",
    "print(f\"üóëÔ∏è  Removed {missing_description:,} rows with missing Description\")\n",
    "print(f\"üìä Rows after removing missing data: {len(df_clean):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Standardize Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Standardizing product descriptions...\n",
      "‚úÖ Product descriptions standardized\n"
     ]
    }
   ],
   "source": [
    "# Standardize product descriptions\n",
    "print(\"üîß Standardizing product descriptions...\")\n",
    "df_clean['Description'] = df_clean['Description'].str.strip().str.title()\n",
    "print(\"‚úÖ Product descriptions standardized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Add Derived Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Converting InvoiceDate to datetime...\n",
      "‚úÖ InvoiceDate converted to datetime\n"
     ]
    }
   ],
   "source": [
    "# Convert InvoiceDate to datetime if not already\n",
    "print(\"üìÖ Converting InvoiceDate to datetime...\")\n",
    "df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])\n",
    "print(\"‚úÖ InvoiceDate converted to datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ Adding TotalPrice column...\n",
      "‚úÖ TotalPrice column added\n"
     ]
    }
   ],
   "source": [
    "# Add TotalPrice column\n",
    "print(\"üí∞ Adding TotalPrice column...\")\n",
    "df_clean['TotalPrice'] = df_clean['Quantity'] * df_clean['Price']\n",
    "print(\"‚úÖ TotalPrice column added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Adding InvoiceYearMonth column...\n",
      "‚úÖ InvoiceYearMonth column added\n"
     ]
    }
   ],
   "source": [
    "# Add InvoiceYearMonth for monthly trends\n",
    "print(\"üìÖ Adding InvoiceYearMonth column...\")\n",
    "df_clean['InvoiceYearMonth'] = df_clean['InvoiceDate'].dt.to_period('M').astype(str)\n",
    "print(\"‚úÖ InvoiceYearMonth column added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alihasan/retail-pricing-mba\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Save Clean Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned transactions saved to: /Users/alihasan/retail-pricing-mba/data_clean/transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned transactions\n",
    "df_clean.to_csv(DATA_CLEAN / \"transactions.csv\", index=False)\n",
    "print(f\"‚úÖ Cleaned transactions saved to: {DATA_CLEAN / 'transactions.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Products: 4,445, Customers: 4,317\n",
      "üìÑ Saved: /Users/alihasan/retail-pricing-mba/data_clean/products.csv\n",
      "üìÑ Saved: /Users/alihasan/retail-pricing-mba/data_clean/customers.csv\n",
      "üéâ Data cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Create and save dimension tables (robust)\n",
    "# ---------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Make sure DATA_CLEAN exists (you already defined ROOT/DATA_CLEAN at the top)\n",
    "DATA_CLEAN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Handle possible column name variants for Customer ID\n",
    "cust_col = None\n",
    "for candidate in [\"Customer ID\", \"Customer_ID\", \"CustomerID\", \"Customer Id\"]:\n",
    "    if candidate in df_clean.columns:\n",
    "        cust_col = candidate\n",
    "        break\n",
    "if cust_col is None:\n",
    "    raise KeyError(\"Could not find a Customer ID column in df_clean. \"\n",
    "                   \"Tried: 'Customer ID', 'Customer_ID', 'CustomerID', 'Customer Id'.\")\n",
    "\n",
    "# Build dimension frames\n",
    "products_df = df_clean[[\"StockCode\", \"Description\"]].drop_duplicates()\n",
    "customers_df = df_clean[[cust_col, \"Country\"]].drop_duplicates()\n",
    "customers_df = customers_df.rename(columns={cust_col: \"Customer_ID\"})  # standardize name\n",
    "\n",
    "# Save using the resolved project path\n",
    "products_df.to_csv(DATA_CLEAN / \"products.csv\", index=False)\n",
    "customers_df.to_csv(DATA_CLEAN / \"customers.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Products: {len(products_df):,}, Customers: {len(customers_df):,}\")\n",
    "print(f\"üìÑ Saved: {DATA_CLEAN / 'products.csv'}\")\n",
    "print(f\"üìÑ Saved: {DATA_CLEAN / 'customers.csv'}\")\n",
    "print(\"üéâ Data cleaning complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
